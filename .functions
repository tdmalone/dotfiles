#!/usr/bin/env bash
# shellcheck shell=bash

####################################################################################################
# Tim's shell functions
# https://github.com/tdmalone/dotfiles/blob/master/.functions
#
# See also: https://github.com/tdmalone/dotfiles/blob/master/.aliases
#
# Copyright (c) 2018-2019 Tim Malone
# License: https://github.com/tdmalone/dotfiles/blob/master/LICENSE
#
# Sorted by category and then (generally) alphabetically
# Any sensitive information is expected to be provided by environment variables in a separate file
#
# DISCLAIMER:
# These have been written for my use-case only and have not been thoroughly tested in different
# circumstances. I use macOS with zsh and additional GNU utils, and generally try to keep all
# third-party tools fairly up-to-date. Your mileage may vary on different platforms and versions.
####################################################################################################

red="\\033[00;31m"
olive="\\033[00;33m"
blue="\\033[00;36m"
normal="\\033[0m"

####################################################################################################
# Assorted functions
####################################################################################################

##########################
# New unsorted
##########################

# ...

##########################
# Sorted assorted
##########################

# Make sudo work with aliases. May not work properly though...
# @see https://askubuntu.com/a/22043/421637

# Allows one to pass a an argument via stdin to 'date'
# eg. echo "2019-06-15T03:57:14Z" | date_stdin -juf "%Y-%m-%dT%H:%M:%SZ"
date_stdin() {
  read -r d
  date "$@" "${d}"
}

# Gives a relative time
relative() {

  now="$(date -u +%s)"
  then="${1}"

  result="$(( now - then ))"

  one_second="$(( 1 ))"
  one_minute="$(( one_second * 60 ))"
  one_hour="$(( one_minute * 60 ))"
  one_day="$(( one_hour * 24 ))"
  one_week="$(( one_day * 7 ))"
  one_month="$(( one_day * 31 ))"
  one_year="$(( one_day * 365 ))"

  if [ "${result}" -ge "${one_year}" ]; then
    result="$(( result / 60 / 60 / 24 / 7 / 31 / 365 ))y"
  elif [ "${result}" -ge "${one_month}" ]; then
    result="$(( result / 60 / 60 / 24 / 7 / 31 ))mth"
  elif [ "${result}" -ge "${one_week}" ]; then
    result="$(( result / 60 / 60 / 24 / 7 ))w"
  elif [ "${result}" -ge "${one_day}" ]; then
    result="$(( result / 60 / 60 / 24 ))d"
  elif [ "${result}" -ge "${one_hour}" ]; then
    result="$(( result / 60 / 60 ))h"
  elif [ "${result}" -ge "${one_minute}" ]; then
    result="$(( result / 60 ))m"
  else
    result+="s"
  fi

  echo "${result}"

} # relative

# Runs provided command in all the (direct) subdirectories, clearly printing out the directory names
# Skips the current directory, and skips hidden directories
run_in_subs() {
  echo
  find . -type d -mindepth 1 -maxdepth 1 -not -path '*/\.*' -print0 \
    | sort --zero-terminated --human-numeric-sort \
    | xargs -0 -I % bash -c "cd % && echo :: % :: && echo && $*; echo"
}

####################################################################################################
# Third party programs & services
####################################################################################################

##########################
# Ansible
##########################

# 'Ansible grep' - usage 'ang something' - designed originally for use in the Astute Ansible repo, but might be useful
# elsewhere as well. Note that the final grep is only used to get colouring back.
ang() {
  git grep --ignore-case "$1" | grep -v "\.sql:" | grep -v "\.js:" | grep -v "\.css:" | grep "$1"
}

apmv() {
  ANSIBLE_VAULT_PASSWORD_FILE=~/.ansible/$1 apm
}

aves() {
  ANSIBLE_VAULT_PASSWORD_FILE=~/.ansible/$1 ansible-vault encrypt_string
}

avds() {
  ANSIBLE_VAULT_PASSWORD_FILE=~/.ansible/$1 ansible-vault decrypt
}

##########################
# AWS
# see also: AWS EC2, AWS EKS
##########################

areset() {
  unset AWS_ACCESS_KEY_ID
  unset AWS_SECRET_ACCESS_KEY
  unset AWS_SESSION_TOKEN
  export AWS_PROFILE="${AWS_TIM_DESIRED_PROFILE}"
  aupd
}

asudo() {

  ACCOUNT_NUMBER="${1:-}"
  ACCOUNT_FRIENDLY_NAME="${2:-}"
  ROLE_NAME="${3:-OrganizationAccountAccessRole}"

  if [ -z "${ACCOUNT_NUMBER}" ]; then ACCOUNT_NUMBER="${AWS_WORK_TIM_ACCOUNT_ID}"; fi

  amfa

  if [ -z "${ACCOUNT_FRIENDLY_NAME}" ]; then ACCOUNT_FRIENDLY_NAME="${ACCOUNT_NUMBER}"; fi
  PROFILE_NAME="${AWS_PROFILE}-${ACCOUNT_FRIENDLY_NAME}"

  echo "Assuming role..."
  CREDS="$(awsar "${ROLE_NAME}" "${ACCOUNT_NUMBER}" "silent")"

  awscs aws_access_key_id "$(echo "${CREDS}" | jqr .Credentials.AccessKeyId)" --profile "${PROFILE_NAME}"
  awscs aws_secret_access_key "$(echo "${CREDS}" | jqr .Credentials.SecretAccessKey)" --profile "${PROFILE_NAME}"
  awscs aws_session_token "$(echo "${CREDS}" | jqr .Credentials.SessionToken)" --profile "${PROFILE_NAME}"
  awscs expiration "$(echo "${CREDS}" | jqr .Credentials.Expiration | sed -e 's/T/ /' -e 's/Z/ /')" --profile "${PROFILE_NAME}"

  export AWS_PROFILE="${PROFILE_NAME}"

  echo
  echo -n "Using: " && echo "${CREDS}" | jqr .AssumedRoleUser.Arn
  echo -n "Until: " && echo "${CREDS}" | jqr .Credentials.Expiration

} # asudo

awsar() {

  ROLE_NAME="${1}"
  ACCOUNT_NUMBER="${2:-}"
  MODE="${3:-}"

  if [ -z "${ACCOUNT_NUMBER}" ]; then ACCOUNT_NUMBER="${AWS_WORK_MASTER_ACCOUNT_ID}"; fi

  # TODO: Remove hyphens in account number (to make it easier to copy from a hyphen'ed display).
  # TODO: Accept aliases and map them to account numbers, probably stored in env vars?

  if [ "${MODE}" != "silent" ]; then
    echo
    echo "Assuming ${ROLE_NAME} in ${ACCOUNT_NUMBER}..."
  fi

  sts assume-role --role-arn "arn:aws:iam::${ACCOUNT_NUMBER}:role/${ROLE_NAME}" --role-session-name "$(whoami)"

}

dam() {
  sts decode-authorization-message --encoded-message "${1}" | jq '.DecodedMessage | fromjson'
}

# Compares the last two versions of an AWS SSM Parameter.
alias ssmdiff='${TIM_WORK_HOMEDIR}/tools/tim-tools/ssmdiff'
# ssmdiff() {

#   parameter_name="${1}"
#   data="$(aws ssm get-parameter-history --name "${parameter_name}" --with-decryption)"

#   current="$(echo "${data}" | jq -j ".Parameters[-1]")"
#   old="$(echo "${data}" | jq -j ".Parameters[-2]")"

#   current_value="$(echo "${current}" | jq ".Value | fromjson")"
#   old_value="$(echo "${old}" | jq ".Value | fromjson")"

#   # Print out a header with the version numbers and dates.
#   # The date are timestamps. They're stripped of their decimal points and passed to `date` (which
#   # doesn't take stdin and also doesn't strip trailing spaces).
#   echo
#   echo -n "Comparing version "
#   echo "${old}" | jq -j ".Version"
#   echo -n " ("
#   echo "${old}" | jq ".LastModifiedDate" | sed 's/\..*//' | date_stdin -r | tr -d "\n"
#   echo -n ") and "
#   echo "${current}" | jq -j ".Version"
#   echo -n " ("
#   echo "${current}" | jq ".LastModifiedDate" | sed 's/\..*//' | date_stdin -r | tr -d "\n"
#   echo ") of ${parameter_name}:"

#   echo
#   diff <(echo "${old_value}") <(echo "${current_value}") || true # We're always expecting a diff, so we don't want a non-zero exit code here.

# }

##########################
# AWS EC2
# see also: AWS
##########################

# TODO: Ignore terminated instances.
instance_id() {

  # Replaces dots with dashes to match our instance Name tags.
  INSTANCE_NAME="${1//./-}"

  ec2 describe-instances --filters "Name=tag:Name,Values=${INSTANCE_NAME}" | jqr ".Reservations[0].Instances[0].InstanceId"
}

# Outputs available marketplace-listed (aka second-hand) reserved instances to JSON.
# May take some time to gather data from the EC2 API.
#
# https://docs.aws.amazon.com/cli/latest/reference/ec2/describe-reserved-instances-offerings.html
# Might be useful? https://github.com/TerbiumLabs/check-reserved-instances
#
# Note that, if nothing else, 'no up-front' convertible one year RIs are pretty much a no-brainer!
# (probably won't find them on the marketplace though, right?)
#
# Also note: the 'reserved instance saving' correlates with how much the instance will have to be
# running to benefit from that saving. eg. a 41% saving? The instance has to be running at least
# 59% of the time to break even! This means under some circumstances you _can_ still reserve a
# part-time instance.
reserved_instances() {

  months="${1:-1}" # Default to 1 month if not provided (1 month is the minimum).
  filename="$( mktemp )"

  one_day="$((60 * 60 * 24))"
  one_month="$((one_day * 30))"

  ec2 describe-reserved-instances-offerings --product-description "Linux/UNIX" --filters "Name=marketplace,Values=true" --filters "Name=duration,Values=$(( one_month * months ))" > "${filename}"

  # TODO: Include an option for adding the AZ filter '--filters Name=availability-zone,Values=a'?

  code "${filename}"

}

snapshot() {
  ec2 create-snapshot --volume-id "$( volume_id "${1}" )"
}

start_instance() {
  echo
  echo "Starting ${1}..."
  echo
  ec2 start-instances --instance-ids "$( instance_id "${1}" )"
}

stop_instance() {
  echo
  echo "Stopping ${1}..."
  echo
  ec2 stop-instances --instance-ids "$( instance_id "${1}" )"
}

terminate_instance() {
  echo
  echo "About to terminate ${1} - press any key to continue or Ctrl+C to quit..."
  read answer
  echo
  ec2 terminate-instances --instance-ids "$( instance_id "${1}" )"
}

volume_id() {

  # Replaces dots with dashes to match our instance Name tags.
  VOLUME_NAME="${1//./-}"

  ec2 describe-volumes --filters "Name=tag:Name,Values=${VOLUME_NAME}" | jqr ".Volumes[0].VolumeId"
}

##########################
# AWS EKS
# see also: Kubernetes
##########################

kunnel() {
  echo
  sudo ps ax | grep ssh | grep fNL
  sudo ps ax | grep ssh | grep fNL | cut -d " " -f 1 | xargs sudo kill
  echo
  echo Tunnel killed.
  echo
}

kubernetic() {
  cluster_name="$1"
  if [ -z "${cluster_name}" ]; then echo "Please provide a cluster name."; return 0; fi
  token="$(aws-iam-authenticator token --cluster-id "${cluster_name}" | jqr ".status.token")"
  kc set-credentials kubernetic --token="${token}"
}

##########################
# GPG
##########################

# Given a filename with a gpg extension, decrypts it and outputs it with the same filename -
# but without the extension.
gpgdc() {
  gpg --output "${1%.gpg}" --decrypt "$1"
}

##########################
# Kubernetes
# see also: AWS EKS
##########################

kbash() {
  ke "${1}" -it -- "${2:-bash}"
}

# from @droctothorpe on hangops Slack
# @see https://hangops.slack.com/archives/C0GFYENRG/p1561587759269600
kgew() {
  kge --all-namespaces --watch \
  -o 'go-template={{.lastTimestamp}} ^ {{.involvedObject.kind}} ^ {{.message}} ^ ({{.involvedObject.name}}){{"\n"}}' \
  | awk -F^ \
  -v black=$(tput setaf 0) \
  -v red=$(tput setaf 1) \
  -v green=$(tput setaf 2) \
  -v yellow=$(tput setaf 3) \
  -v blue=$(tput setaf 4) \
  -v magenta=$(tput setaf 5) \
  -v cyan=$(tput setaf 6) \
  -v white=$(tput setaf 7) \
  '{
      $1=blue $1
      $2=green $2
      $3=white $3
  }
  1'
}

# Scales a deployment down to 0 and back up to what it is, effectively restarting it.
krestart() {
  deployment_name="${1}"
  current_replicas="$(kgd "${deployment_name}" -o json | jq '.spec.replicas')"
  k scale --replicas=0 deployment "${deployment_name}"
  k scale --replicas="${current_replicas}" deployment "${deployment_name}"
  echo && kgd "${deployment_name}"
  echo && kp | grep "${deployment_name}"
}

# kupgrade 10001 next
# kupgrade 10002 current
# kupgrade 10003 previous
# kupgrade 10004 current
kupgrade() {

  portal_id="${1}"
  version_name="${2}"

  command="AP_Command_Upgrade"
  pod_name="$(kp -l "version-name=${version_name}" -o jsonpath='{.items[0].metadata.name}')"

  echo
  echo "Running ${command} on ${pod_name} for portal ID ${portal_id}..."
  echo

  ke "${pod_name}" -- /opt/code/astute/cli/ap.sh --portal_id "${portal_id}" --command "${command}"

}

# Prints out a nice list of nodes with all their pertinent data in columns.
#
# WARNING: This makes use of 'kubectl describe', due to deficiencies in the amount of data available
# through 'kubectl get'. 'describe' does not have a machine-readable output option, so it's possible
# the implementation could change in later releases.
nodes() {

  get_data="$(kn --output json)" # This is easily parsable.
  describe_data="$(kdn)"         # This contains much more detail but is NOT easily parsable.

  node_count="$(echo "${get_data}" | jqj '.items | length')"

  date_fmt="%Y-%m-%dT%H:%M:%SZ"

  out=""
  out+="NAME         |IP ADDRESS  |ALLOC. CPU  |ALLOC. MEM   |PODS   |AGE|H/BEAT|VERSION|INSTANCE|AZ|READY|TAINTS\n"
  out+="=============|============|============|=============|=======|===|======|=======|========|==|=====|======\n"

  # shellcheck disable=SC2051 # We're writing for zsh
  for i in {0..$((node_count - 1))}; do

    node_data="$(echo "${get_data}" | jqj '.items['$i']')"
    node_name="$(ecn "${node_data}" | jqj '.metadata.name')"

    extended_node_data="$(echo "${describe_data}" | sed -En "/Name:[[:space:]]+${node_name}/,/^$/p" )"
    allocated_resources="$(echo "${extended_node_data}" | grep -A7 "Allocated resources:")"

    pod_count="$(echo "${extended_node_data}" | grep "Non-terminated Pods:" | awk '{print $3}' | sed 's/[^0-9]//g')"

    cpu_allocated_percent="$(echo "${allocated_resources}" | grep cpu | awk '{print $3}' | sed 's/[^0-9%]//g')"
    mem_allocated_percent="$(echo "${allocated_resources}" | grep memory | awk '{print $3}' | sed 's/[^0-9%]//g')"

    age="$(ecn "${node_data}" | jqj '.metadata.creationTimestamp' | date_stdin -juf "${date_fmt}" "+%s")"
    heartbeat="$(ecn "${node_data}" | jqj '.status.conditions[] | select(.type == "Ready").lastHeartbeatTime' | date_stdin -juf "${date_fmt}" "+%s")"
    mem_kb="$(ecn "${node_data}" | jqj '.status.capacity.memory' | sed 's/[^0-9]//g')"
    mem_mb="$(( mem_kb / 1024 ))"

    age_relative="$(relative "${age}")"
    heartbeat_relative="$(relative "${heartbeat}")"

    out+="$(ecn "${node_data}" | jqj '.status.addresses[] | select(.type == "Hostname").address')|"
    out+="$(ecn "${node_data}" | jqj '.status.addresses[] | select(.type == "InternalIP").address')|"
    out+="${(l:3:)cpu_allocated_percent} / $(ecn "${node_data}" | jqj '.status.capacity.cpu') vCPU|"
    out+="${(l:3:)mem_allocated_percent} / ${mem_mb} MB|"
    out+="${(l:2:)pod_count} / $(ecn "${node_data}" | jqj '.status.capacity.pods')|"
    out+="${(l:3:)age_relative}|"
    out+="${(l:3:)heartbeat_relative}|"
    out+="$(ecn "${node_data}" | jqj '.status.nodeInfo.kubeletVersion')|"
    out+="$(ecn "${node_data}" | jqj '.metadata.labels["beta.kubernetes.io/instance-type"]')|"
    out+="$(ecn "${node_data}" | jqj '.metadata.labels["failure-domain.beta.kubernetes.io/zone"]' | sed 's/.*\(.\)/\1/')|"
    out+="$(ecn "${node_data}" | jqj '.status.conditions[] | select(.type == "Ready").status')|"
    out+="$(ecn "${node_data}" | jqj '.spec.taints[]?.effect')|"
    out+="\n"

  done

  echo "${out}" | column -ts "|"

}

##########################
# Python
##########################

# Simply adds an item to requirements.txt - and sorts and removes duplicates.
# Does not actually install it.
pipadd(){
  echo "${1}" >> requirements.txt

  # De-dupe.
  # @see https://stackoverflow.com/questions/9377040/remove-duplicate-entries-using-a-bash-script
  #awk '!a[$0]++' requirements.txt # This works, but can't be redirected back to the same file.
  perl -i -ne 'print if ! $a{$_}++' requirements.txt

  cat requirements.txt
}

##########################
# Terraform
##########################

tatf() {
  echo "Looking for matches..."
  resources="$(tfind $1)"
  args=""
  while read -r resource; do
    args="-target '${resource}' ${args}"
  done <<< "${resources}"
  args="${args//mod./module.}" # Allow 'module' to be shortened as 'mod'
  echo "About to run ${olive}terraform apply ${args}${normal}"
  echo "Press Ctrl+C within 2 seconds to cancel..."
  sleep 2
  echo "Waiting for Terraform..."
  eval "terraform apply ${args}"
}

# Given one argument with a common Terraform resource address, runs it into the format required for (un)tainting.
# Terraform 0.11 only.
# eg. tf_convert_module taint module.main.module.man.null_resource.provisioner
tf_convert_module() {

  command="$1"
  full_address="$2"

  module_arg=""
  resource="${full_address}"

  # Allow 'module' to be shortened as 'mod'
  full_address="${full_address//mod./module.}"

  if [[ ${full_address} =~ module\\. ]]; then
    module_arg="-module "

    # sed with extended regexps (-E) due to use of +
    resource="$(echo "${full_address}" | sed -Ee 's/module\.[^\.]+\.//g' )" # Strip all modules
    module_arg+="$(echo "${full_address}" | sed -Ee 's/module\.([^\.]+)/\1/g')" # Remove 'module.' from module names
    module_arg="${module_arg%\.${resource}} " # Strip remaining resource name
  fi

  echo "Converted to 'terraform ${command} ${module_arg}${resource}'"
  eval "terraform ${command} ${module_arg}${resource}"
}

# Makes -target command lines shorter by allowing 'mod' instead of 'module'.
# This can probably be made a lot simpler...
tf_target() {

  command=${1}
  target=${2}
  shift 2;
  additional_args=$@

  command_to_run="$command -target $target $additional_args"
  command_to_run="${command_to_run//mod./module.}"

  # Remove trailing spaces (probably more complicated than it needs to be...)
  command_to_run="${command_to_run%"${command_to_run##*[![:space:]]}"}"

  echo -e "Running ${olive}${command_to_run}${normal}..."
  eval "$command_to_run"

}

tfsp() {
  tempfile=$(mktemp)
  t state pull > "${tempfile}"
  code "${tempfile}"
}
